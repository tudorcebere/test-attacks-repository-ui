URL: https://arxiv.org/abs/2302.07956
BibTex (Please add a bibtex entry for this paper to facilitate easy citations): "@inproceedings{nasr2023tight,\n\
  \  title={Tight Auditing of Differentially Private Machine Learning},\n\tauthor={Milad\
  \ Nasr and Jamie Hayes and Thomas Steinke and Borja Balle and Florian Tram{\\`e}r\
  \ and Matthew Jagielski and Nicholas Carlini and Andreas Terzis},\n\tbooktitle={USENIX\
  \ Security},\n\tyear = {2023}\n}"
Authors: Milad Nasr, Jamie Hayes, Thomas Steinke, Borja Balle, Florian Tram√®r, Matthew
  Jagielski, Nicholas Carlini, Andreas Terzis
Title: Tight Auditing of Differentially Private Machine Learning
Short Description: Designs an improved auditing scheme that yields tight privacy estimates
  for natural (not adversarially crafted) datasets -- if the adversary can see all
  model updates during training. Moreover, the auditing scheme requires only two training
  runs (instead of thousands) to produce tight privacy estimates, by adapting recent
  advances in tight composition theorems for differential privacy.
Data Type: Image
Type of Release: Predictive-Model
Threat Model --- Attacker Objective: Membership-Inference
Threat Model --- Attacker Capabilities: .nan
Research Type: Empirical
Links to Artifacts: .nan
Comments: .nan
Submitter (your name, affiliation): Georgi Ganev, UCL
Publication Year: 2023
